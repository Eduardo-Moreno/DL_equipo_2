# Similitud Semántica::BERT
***

### Objetivo

El objetivo del presente trabajo, es estudiar el modelo BERT (Bidirectional Encoder Representatios from Transformers), el cual es un modelo bidireccional para el análisis de lenguaje natural que busca encontrar la similitud entre 2 oraciones, en cuanto a su significado.

### Descripción del repo y requerimientos:

- Utilizamos Google Colab (GRU) para el estudio del modelo del desempeño del modelo: `notebooks/`.


## Equipo 2

| Nombre | User Github | 
|:---:|:---:|
| Hécttor Efrén Guadarrama | HecttorJ | 
| Eduardo Moreno | Eduardo-Moreno| 
| Miguel López Cruz | Lobolc| 
