<p align="center">
  <img src="https://github.com/Eduardo-Moreno/DL_equipo_2/blob/main/images/BERT.png">
</p>

# Similitud Semántica::BERT
***

### Objetivo

El objetivo del presente trabajo, es estudiar el modelo **BERT** (*Bidirectional Encoder Representatios from Transformers*), el cual es un modelo bidireccional para el análisis de lenguaje natural que busca encontrar la similitud entre 2 oraciones, en cuanto a su significado.

### Descripción del repo:

- Utilizamos Google Colab (GRU) para el estudio del modelo del desempeño del modelo: `notebooks/`.
- El reporte, código y resumen técnico se encuentra en la carpeta `documentation/`
- En la carpeta `models/` se encuentran los modelos que evaluaron el desempeño de BERT bajo distintas configuraciones de los hiperparámetros.


## Equipo 2

| Nombre | User Github | 
|:---:|:---:|
| Hécttor Efrén Guadarrama | HecttorJ | 
| Eduardo Moreno | Eduardo-Moreno| 
| Miguel López Cruz | Lobolc| 
